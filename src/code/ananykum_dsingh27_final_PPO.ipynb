{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pZS6HY3O2fN",
    "outputId": "179b1316-7294-4dc9-8d20-fb039f1fbc04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[atari] in /user/dsingh27/.local/lib/python3.9/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/scipy-bundle/2021.10/lib/python3.9/site-packages (from gymnasium[atari]) (1.21.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium[atari]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/typing-extensions/4.3.0/lib/python3.9/site-packages (from gymnasium[atari]) (4.3.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium[atari]) (7.0.1)\n",
      "Requirement already satisfied: shimmy<1.0,>=0.1.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium[atari]) (3.5.0)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in /user/dsingh27/.local/lib/python3.9/site-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.8.1)\n",
      "Requirement already satisfied: importlib-resources in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (5.2.2)\n",
      "\u001b[33mDEPRECATION: matlabengineforpython R2021b has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of matlabengineforpython or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[accept-rom-license] in /user/dsingh27/.local/lib/python3.9/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/scipy-bundle/2021.10/lib/python3.9/site-packages (from gymnasium[accept-rom-license]) (1.21.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium[accept-rom-license]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/typing-extensions/4.3.0/lib/python3.9/site-packages (from gymnasium[accept-rom-license]) (4.3.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium[accept-rom-license]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium[accept-rom-license]) (7.0.1)\n",
      "Requirement already satisfied: autorom~=0.4.2 in /user/dsingh27/.local/lib/python3.9/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (0.4.2)\n",
      "Requirement already satisfied: click in /user/dsingh27/.local/lib/python3.9/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (8.1.7)\n",
      "Requirement already satisfied: requests in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /user/dsingh27/.local/lib/python3.9/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (4.66.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /user/dsingh27/.local/lib/python3.9/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium[accept-rom-license]) (3.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (3.2)\n",
      "\u001b[33mDEPRECATION: matlabengineforpython R2021b has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of matlabengineforpython or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable_baselines3 in /user/dsingh27/.local/lib/python3.9/site-packages (2.3.2)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /user/dsingh27/.local/lib/python3.9/site-packages (from stable_baselines3) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/scipy-bundle/2021.10/lib/python3.9/site-packages (from stable_baselines3) (1.21.3)\n",
      "Requirement already satisfied: torch>=1.13 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/pytorch/1.13.1-CUDA-11.8.0/lib/python3.9/site-packages (from stable_baselines3) (1.13.1)\n",
      "Requirement already satisfied: cloudpickle in /user/dsingh27/.local/lib/python3.9/site-packages (from stable_baselines3) (3.0.0)\n",
      "Requirement already satisfied: pandas in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/scipy-bundle/2021.10/lib/python3.9/site-packages (from stable_baselines3) (1.3.4)\n",
      "Requirement already satisfied: matplotlib in /user/dsingh27/.local/lib/python3.9/site-packages (from stable_baselines3) (3.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/typing-extensions/4.3.0/lib/python3.9/site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.3.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (7.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /user/dsingh27/.local/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /user/dsingh27/.local/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /user/dsingh27/.local/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /user/dsingh27/.local/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/pillow/9.2.0/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from matplotlib->stable_baselines3) (5.2.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from pandas->stable_baselines3) (2021.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium<0.30,>=0.28.1->stable_baselines3) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/Compiler/gcccore/11.2.0/python/3.9.6/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "\u001b[33mDEPRECATION: matlabengineforpython R2021b has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of matlabengineforpython or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: utils in /user/dsingh27/.local/lib/python3.9/site-packages (1.0.2)\n",
      "\u001b[33mDEPRECATION: matlabengineforpython R2021b has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of matlabengineforpython or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[atari]\n",
    "!pip install gymnasium[accept-rom-license]\n",
    "!pip install stable_baselines3\n",
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P1FLnpJeO6IP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/histogram_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/histogram_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/histogram_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _HISTOGRAMPROTO = _descriptor.Descriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _DATATYPE = _descriptor.EnumDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/tensorflow/2.11.0-CUDA-11.8.0/lib/python3.9/site-packages/tensorboard/compat/proto/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORPROTO = _descriptor.Descriptor(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "from collections import deque, Counter, namedtuple, defaultdict\n",
    "from itertools import count\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.atari_wrappers import ClipRewardEnv, FireResetEnv, MaxAndSkipEnv, NoopResetEnv\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as nn_utils\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EtrLMIkPO5_I"
   },
   "outputs": [],
   "source": [
    "class EnvironmentSetup:\n",
    "    ENV_ARGS = {'id': \"PongDeterministic-v4\"}\n",
    "    SEED = 1\n",
    "    OUTPUT_DIR = 'output'\n",
    "    NUM_ENVS = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.root_dir = os.getcwd()\n",
    "        self.output_path = os.path.join(self.root_dir, self.OUTPUT_DIR)\n",
    "        self.create_output_dir()\n",
    "        self.set_random_seeds()\n",
    "        print('device = ', self.device)\n",
    "\n",
    "    def create_output_dir(self):\n",
    "        if not os.path.exists(self.output_path):\n",
    "            os.makedirs(self.output_path)\n",
    "\n",
    "    def set_random_seeds(self):\n",
    "        random.seed(self.SEED)\n",
    "        np.random.seed(self.SEED)\n",
    "        torch.manual_seed(self.SEED)\n",
    "\n",
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        self.lr = 3e-4\n",
    "        self.num_steps = 2048\n",
    "        self.num_envs = 3\n",
    "        self.num_iterations = 800\n",
    "        self.gamma = 0.99\n",
    "        self.gae_lambda = 0.95\n",
    "        self.update_epochs = 10\n",
    "        self.clip_coef = 0.2\n",
    "        self.entropy_coef = 0.01\n",
    "        self.vf_coef = 0.5\n",
    "        self.max_grad_norm = 0.5\n",
    "        self.mini_batch_count = 64\n",
    "        self.update_plots = 10\n",
    "        self.output_dir = 'output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T0ST2DAyPzug"
   },
   "outputs": [],
   "source": [
    "class EnvironmentCreator:\n",
    "    def __init__(self, env_args):\n",
    "        self.env_args = env_args\n",
    "\n",
    "    def make_env(self):\n",
    "        env = gym.make(**self.env_args)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        env = NoopResetEnv(env, noop_max=30)\n",
    "        env = MaxAndSkipEnv(env, skip=4)\n",
    "        env = ClipRewardEnv(env)\n",
    "        env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
    "        env = gym.wrappers.GrayScaleObservation(env)\n",
    "        env = gym.wrappers.FrameStack(env, 4)\n",
    "        return env\n",
    "\n",
    "class Plotter:\n",
    "    @staticmethod\n",
    "    def plot(history, show=False, save_path=None):\n",
    "        sns.lineplot(y=history['reward'], x=list(range(len(history['reward']))))\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, agent, env_creator, episodes=10):\n",
    "        self.agent = agent\n",
    "        self.env_creator = env_creator\n",
    "        self.episodes = episodes\n",
    "\n",
    "    def evaluate(self):\n",
    "        envs = gym.vector.SyncVectorEnv([lambda: self.env_creator.make_env()])\n",
    "        self.agent.eval()\n",
    "        total_rewards = []\n",
    "        next_obs, _ = envs.reset()\n",
    "\n",
    "        while len(total_rewards) < self.episodes:\n",
    "            next_obs = torch.Tensor(next_obs)\n",
    "            with torch.no_grad():\n",
    "                action, log_prob, _, value = self.agent.get_action_and_value(next_obs)\n",
    "            next_obs, reward, terminated, truncated, info = envs.step(action.numpy())\n",
    "\n",
    "            if 'final_info' in info:\n",
    "                for data in info['final_info']:\n",
    "                    if data:\n",
    "                        reward = data['episode']['r'][0]\n",
    "                        total_rewards.append(reward)\n",
    "\n",
    "        return total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "me3_pgRjQ2jz"
   },
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, action_space, hidden_size=512):\n",
    "        super().__init__()\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Linear(7 * 7 * 64, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.actor = nn.Linear(hidden_size, self.action_space.n)\n",
    "        self.critic = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        action_probs = self.actor(x)\n",
    "        state_values = self.critic(x)\n",
    "        return action_probs, state_values\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits, value = self.forward(x / 255.0)  \n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        log_prob = probs.log_prob(action)\n",
    "        entropy = probs.entropy()\n",
    "        return action, log_prob, entropy, value\n",
    "\n",
    "    def get_value(self, x):\n",
    "        _, value = self.forward(x / 255.0)\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpYSmC2wRHfd",
    "outputId": "028d3a75-523f-49f1-a699-4e05400aed81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape =  torch.Size([1, 4, 84, 84])\n",
      "action shape =  torch.Size([1])\n",
      "log prob shape =  torch.Size([1])\n",
      "entropy shape =  torch.Size([1])\n",
      "value shape =  torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "class AgentTester:\n",
    "    def __init__(self, env_creator, num_envs=1):\n",
    "        self.envs = gym.vector.SyncVectorEnv(\n",
    "            [lambda: env_creator.make_env() for _ in range(num_envs)]\n",
    "        )\n",
    "        assert isinstance(self.envs.single_action_space, gym.spaces.Discrete), 'Only discrete action is supported'\n",
    "\n",
    "    def test_agent(self, agent):\n",
    "        obs, info = self.envs.reset()\n",
    "        obs = torch.tensor(obs).float()\n",
    "        print('obs shape = ', obs.shape)\n",
    "\n",
    "        action, log_prob, entropy, value = agent.get_action_and_value(obs)\n",
    "\n",
    "        print('action shape = ', action.shape)\n",
    "        print('log prob shape = ', log_prob.shape)\n",
    "        print('entropy shape = ', entropy.shape)\n",
    "        print('value shape = ', value.shape)\n",
    "\n",
    "    def close_envs(self):\n",
    "        self.envs.close()\n",
    "\n",
    "\n",
    "# env_args = {'id': \"PongDeterministic-v4\"}\n",
    "# env_creator = EnvironmentCreator(env_args)\n",
    "# tester = AgentTester(env_creator, EnvironmentSetup.NUM_ENVS)\n",
    "# agent = Agent(action_space=tester.envs.single_action_space)\n",
    "\n",
    "# tester.test_agent(agent)\n",
    "# tester.close_envs()\n",
    "\n",
    "\n",
    "# del agent, tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jYFkRAh4RbSU"
   },
   "outputs": [],
   "source": [
    "class TrainingEnvironment:\n",
    "    def __init__(self, config, num_envs, device):\n",
    "        self.config = config\n",
    "        self.envs = gym.vector.AsyncVectorEnv(\n",
    "            [lambda: EnvironmentCreator({'id': \"PongDeterministic-v4\"}).make_env() for _ in range(num_envs)]\n",
    "        )\n",
    "        self.agent = Agent(self.envs.single_action_space).to(device)\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(self.agent.parameters(), lr=self.config.lr, eps=1e-5)\n",
    "        self.check_initialization()\n",
    "        self.setup_directories()\n",
    "        self.best_score = float('-inf')\n",
    "\n",
    "    def check_initialization(self):\n",
    "        save_path = os.path.join(self.config.output_dir, 'ppo_checkpoint.torch')\n",
    "        if os.path.exists(save_path):\n",
    "            print(\"Loading checkpoint...\")\n",
    "            self.agent.load_state_dict(torch.load(save_path))\n",
    "            print(\"Checkpoint loaded.\")\n",
    "        else:\n",
    "            print(\"Starting from scratch...\")\n",
    "\n",
    "    def setup_directories(self):\n",
    "        self.label = str(uuid.uuid4()).split('-')[0]\n",
    "        self.save_dir = os.path.join(self.config.output_dir, self.label)\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "        self.fig_save_path = os.path.join(self.save_dir, 'plot.png')\n",
    "\n",
    "    def train(self):\n",
    "        M = self.config.num_steps\n",
    "        N = self.config.num_envs\n",
    "        reward_window = deque(maxlen=100)\n",
    "        history = defaultdict(list)\n",
    "        global_step = 0\n",
    "        self.best_score = float('-inf')\n",
    "        loss = float('inf')\n",
    "\n",
    "\n",
    "        next_obs, _ = self.envs.reset()\n",
    "        next_obs = torch.tensor(next_obs, device=self.device)\n",
    "        next_done = torch.zeros(N, device=self.device)\n",
    "\n",
    "\n",
    "        obs = torch.zeros((M, N) + self.envs.single_observation_space.shape, device=self.device)\n",
    "        actions = torch.zeros((M, N) + self.envs.single_action_space.shape, device=self.device)\n",
    "        log_probs = torch.zeros((M, N), device=self.device)\n",
    "        rewards = torch.zeros((M, N), device=self.device)\n",
    "        dones = torch.zeros((M, N), device=self.device)\n",
    "        values = torch.zeros((M, N), device=self.device)\n",
    "\n",
    "        self.loop = tqdm(range(self.config.num_iterations), desc=\"Training Loop\")\n",
    "        for iteration in self.loop:\n",
    "            if iteration % self.config.update_plots == 0:\n",
    "                self.plot(history)\n",
    "\n",
    "            for step in range(M):\n",
    "                global_step += N\n",
    "\n",
    "\n",
    "                obs[step] = next_obs\n",
    "                dones[step] = next_done\n",
    "\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    action, log_prob, _, value = self.agent.get_action_and_value(next_obs)\n",
    "                    values[step] = value.flatten()\n",
    "\n",
    "\n",
    "                actions[step] = action\n",
    "                log_probs[step] = log_prob\n",
    "\n",
    "\n",
    "                next_obs, reward, terminated, truncated, info = self.envs.step(action.cpu().numpy())\n",
    "                next_done = torch.logical_or(torch.tensor(terminated), torch.tensor(truncated)).to(self.device)\n",
    "\n",
    "  \n",
    "                rewards[step] = torch.tensor(reward, device=self.device).view(-1)\n",
    "                next_obs = torch.tensor(next_obs, device=self.device)\n",
    "\n",
    " \n",
    "                if 'final_info' in info:\n",
    "                    for data in info['final_info']:\n",
    "                        if data:\n",
    "                            reward = data['episode']['r']\n",
    "                            reward_window.append(reward)\n",
    "                            avg_reward = torch.tensor(list(reward_window)).mean().item()\n",
    "                            history['reward'].append(avg_reward)\n",
    "                            self.loop.set_description(f\"Reward = {avg_reward:.2f}, Global Step = {global_step}, Best Score = {self.best_score:.2f}, Loss = {loss:.2f}\")\n",
    "\n",
    "                            if self.best_score < avg_reward:\n",
    "                                self.best_score = avg_reward\n",
    "                                torch.save(self.agent.state_dict(), os.path.join(self.save_dir, 'ppo_checkpoint_best.torch'))\n",
    "\n",
    "\n",
    "            self.optimize_policy(obs, actions, log_probs, rewards, dones, values, next_obs, next_done)\n",
    "\n",
    "\n",
    "        torch.save(self.agent.state_dict(), os.path.join(self.save_dir, 'final_model.pth'))\n",
    "        print(\"Training completed. Model saved.\")\n",
    "\n",
    "    def plot(self, history):\n",
    "        if history['reward']:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(range(len(history['reward'])), history['reward'], label='Rewards')\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel('Reward')\n",
    "            plt.title('Training Rewards Over Time')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(self.fig_save_path)\n",
    "            plt.close()\n",
    "\n",
    "    def optimize_policy(self, obs, actions, log_probs, rewards, dones, values, next_obs, next_done):\n",
    "        M, N = self.config.num_steps, self.config.num_envs\n",
    "        with torch.no_grad():\n",
    "\n",
    "            next_value = self.agent.get_value(next_obs).reshape(1, -1)\n",
    "            advantages = torch.zeros_like(rewards, device=self.device)\n",
    "            last_gae_lam = 0\n",
    "\n",
    "\n",
    "            for t in reversed(range(M)):\n",
    "                if t == M - 1:\n",
    "                    next_non_terminal = 1.0 - next_done.float()\n",
    "                    next_values = next_value\n",
    "                else:\n",
    "                    next_non_terminal = 1.0 - dones[t + 1].float()\n",
    "                    next_values = values[t + 1]\n",
    "\n",
    "                delta = rewards[t] + self.config.gamma * next_values * next_non_terminal - values[t]\n",
    "                advantages[t] = last_gae_lam = delta + self.config.gamma * self.config.gae_lambda * next_non_terminal * last_gae_lam\n",
    "\n",
    "\n",
    "            returns = advantages + values\n",
    "\n",
    "\n",
    "        b_obs = obs.view((-1,) + self.envs.single_observation_space.shape)\n",
    "        b_actions = actions.view((-1,) + self.envs.single_action_space.shape)\n",
    "        b_log_probs = log_probs.view(-1)\n",
    "        b_advantages = advantages.view(-1)\n",
    "        b_returns = returns.view(-1)\n",
    "        b_values = values.view(-1)\n",
    "\n",
    "        batch_size = M * N\n",
    "        mini_batch_size = batch_size // self.config.mini_batch_count\n",
    "        batch_indices = torch.arange(batch_size, device=self.device)\n",
    "\n",
    "        for epoch in range(self.config.update_epochs):\n",
    "\n",
    "            batch_indices = batch_indices[torch.randperm(batch_size)]\n",
    "\n",
    "            for start in range(0, batch_size, mini_batch_size):\n",
    "                end = start + mini_batch_size\n",
    "                mini_indices = batch_indices[start:end]\n",
    "\n",
    "\n",
    "                b_obs_mini = b_obs[mini_indices]\n",
    "                b_actions_mini = b_actions[mini_indices]\n",
    "                b_log_probs_old_mini = b_log_probs[mini_indices]\n",
    "                b_advantages_mini = b_advantages[mini_indices]\n",
    "                b_returns_mini = b_returns[mini_indices]\n",
    "\n",
    "\n",
    "                _, new_log_prob, entropy, new_value = self.agent.get_action_and_value(b_obs_mini, b_actions_mini)\n",
    "\n",
    "\n",
    "                log_ratio = new_log_prob - b_log_probs_old_mini\n",
    "                ratio = torch.exp(log_ratio)\n",
    "                surr1 = ratio * b_advantages_mini\n",
    "                surr2 = torch.clamp(ratio, 1.0 - self.config.clip_coef, 1.0 + self.config.clip_coef) * b_advantages_mini\n",
    "                policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "\n",
    "                value_loss = 0.5 * (new_value.view(-1) - b_returns_mini).pow(2).mean()\n",
    "\n",
    "\n",
    "                loss = policy_loss + self.config.vf_coef * value_loss - self.config.entropy_coef * entropy.mean()\n",
    "\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.agent.parameters(), self.config.max_grad_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "                clip_fraction = (torch.abs(ratio - 1.0) > self.config.clip_coef).float().mean().item()\n",
    "\n",
    "\n",
    "            self.loop.set_description(f\"Loss: {loss.item():.4f}, Clip Frac: {clip_fraction:.2f}, Best Score: {self.best_score:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zgaVue1bT0P3",
    "outputId": "fe0f7dc0-f6ff-49b6-a3e9-8c88066b52d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -0.0153, Clip Frac: 0.29, Best Score: -2.25: 100%|██████████| 800/800 [7:49:44<00:00, 35.23s/it]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig()\n",
    "env_creator = EnvironmentCreator({'id': \"PongDeterministic-v4\"})\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "training_environment = TrainingEnvironment(config, num_envs=1, device=device)\n",
    "training_environment.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
